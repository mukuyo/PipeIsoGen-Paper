\chapter{%
序論}

% 章アブストラクト
配管は気体、液体、粉粒対などの流体を輸送や配線の保護などを目的とする管のことである。
配管は電気配線やケーブルを保護する電気配管や、生活に必要な水を家庭や学校などに輸送する水道管など様々な場面で使用されており、私達の生活において重要な役割を担っている。
そのため、配管を運用するにあたって常に耐久性と安全性を保ち続ける必要性がある。 \\

\section{研究背景}
　BIM とは、Building Information Modeling の略称で、コンピュータ上に建築物や土木構造物などの立体モデルを形成し、設計から維持管理までのプロセスをデジタル化する新しいワークフローの一環である。
このBIMモデリングはこれまでの3Dモデリングとは大きく異なる。従来の3次元モデリングでは平面図などの2次元上で作成した図面を元に別途3次元のモデルを作成していた。
そのため、図面と3次元モデルが連動しておらず、設計変更がある度に図面と3Dモデルの両方を修正する必要があり効率的ではなかった。
しかし、このBIM手法は一つのデータを修正すると全てのデータが連動し、関係する図面の該当箇所が自動修正され、従来の方法よりも高校率で作業を行うことが可能になる。\\
　配管は建築物の中でも日常生活に欠かせない存在である。生活に必要な物資を運用したり電線やケーブルを保護するために使用されるなど幅広い面で活用されているため常に耐久性と安全性が求めらている。
その配管の図面を作成する際にはアイソメトリック（アイソメ）図と呼ばれる立体を斜めから見た視点で表示した等角図が用いられる。
このアイソメ図の最大の特徴が図面を見るだけで配管のルートを一目でイメージしやすくなることだ。設計図には平面図や立体図、系統図など
様々な種類の図面を使用するが、配管の場合、配管同士が複数にも重なり合っているため左右上下からの視点では見分けることが困難である。そのため、アイソメ図は図面を立体的に描画する手法を扱えるだけでなく、
配管のルートや交差する配管の前後関係をイメージしやすくなる。\\
\begin{figure}[htbt]
	\centering
	 \includegraphics[height=75mm]{aisome.eps}
	 \caption{アイソメ図の例}
	 \label{fig:f1}
\end{figure}

アイソメ図を取得するためにはこれまでにLight Detection and Ranging(LIDAR)センサーと呼ばれるレーザー光を使用して離れた場所にある物体の形状や距離を測定できるセンサーを使用していた。
LIDARセンサーは距離情報を活用して3次元情報を取得するだけでなく、測定範囲の広さや取得データの精度が評価されている。しかしその反面、他のセンサーと比較すると高価であるというデメリットを抱えているため、たくさんの人が
使用することは困難であるとされていた。このような背景から近年LIDARセンサーよりも安価なRGBカメラやRGB-Dカメラを用いた認識手法が研究され始めている。
近年の画像認識分野の研究では機械学習を用いた研究が多く取り上げられている。業務効率化や生産性向上、そして人手不足解消を実現できるというメリットがあり、人工知能の導入は加速していくことが予測されている。

\begin{figure}[htbt]
	\centering
	 \includegraphics[height=95mm]{flow.eps}
	 \caption{従来のアイソメ図取得方法}
	 \label{fig:f2}
\end{figure}

\section{既存研究}
機械学習による画像認識分野では画像に写る物体の位置を特定する物体検出や画像の画素ごとに識別を行うセグメンテーション、オブジェクトの位置情報に加えて向きを推定する姿勢推定問題など様々な分野で研究がなされている。
物体検出は画像内で認識したいオブジェクトがどこに存在しているのかをバウンディングボックスを用いて検出するのが一般的である。
その代表的なモデルとしてYOLOを紹介する[10]。このモデルはほぼ同時期に発表されたFast R-CNNと同様に、物体検出に大きな影響を与えた[12]。Convolutional Neural Network(CNN)と呼ばれる畳み込みという操作を
加えたニューラルネットワーク構造を使用してオブジェクトを検出する。CNNの中には畳み込み層やプーリング層といった画像の特徴を抽出する機能が存在し、人手による作業を必要とせず得られた特徴をもとにオブジェクトの認識を行うことができる。
YOLOの特徴は、従来までは境界設定と物体検出を2段階に行っていた作業を一度に処理することで推定速度の高速化を実現することができた。図1.2にYOLOのネットワーク構造を示す。\\
\begin{figure}[htbt]
	\centering
	 \includegraphics[height=75mm]{yolo.eps}
	 \caption{YOLOモデルの検出の流れ}
	 \label{fig:f2}
\end{figure}

まず、入力画像をS*Sのグリッドセルに分割し、各グリッドセルで複数個のバウンディングボックスと各バウンディングボックスの信頼度を計算する。
物体の中心がグリッドセルに存在していた場合に、そのセルが物体を検出するように学習する。次に、バウンディングボックスの推定では各グリッドセルにB個のバウンディングボックスを持ち、それらのボックスの信頼スコアを予測する。
信頼スコアとは背景ではなく認識したい物体が含まれている確率のことである。次に、各グリッドセルは複数のクラスに対する条件付き確率を予測する
算出された条件付きクラス確率と一つ前の個々のバウンディングボックスの信頼スコアを掛け合わせることで、バウンディングボックス毎の
クラスに対する信頼スコアを得ることができる。このスコアを使用しどのバウンディングボックスが正解の物体を推定しているのかを判断している。
これ以降、End-to-Endモデルと呼ばれる入力層から出力層まで全層の重みを一辺に学習する手法が物体検出分野の中で主流となった。\\
一般的な物体検出ではRGB画像を用いた手法が多いが、カラー画像にDepth画像を取り入れた物体検出方法も存在する。Depth画像は物体の奥行き情報や、外光の影響を受けづらいため暗闇の中でも安定してオブジェクトの特徴を捉えることができる点が優れている。
RGB-D画像を用いた物体検出はカラー画像と深度画像をそれぞれ両方畳み込みした値を最後の全結合層で結合するのみの手法が一般的であった[14]。しかし、この手法ではカラー画像と深度画像のそれぞれの特性を維持することはできず、最大限RGB-D画像の利点を活かすことができていなかった。
そこでSPnetモデルではクロス強化モジュール(CIM)を提案することでRGB画像と深度画像から抽出された特徴を維持したまま統合する機能を実現可能にした[13]。\\
　次に、6D姿勢推定問題について紹介する。姿勢推定は物体検出とは違い、位置情報だけでなく回転や向き(Yaw, Pitch, Roll)を求める必要がある。物体の姿勢を求めることができれば配管がどの方向を向いているのかを示すことができアイソメ図作成に大きな利益をもたらす。
姿勢推定問題では物体検出と同様にRGBカメラやRGB-Dカメラを使用した推定方法がある。RGBカメラの姿勢推定問題では古典的な方法はキーポイントを検出し、既知のオブジェクトモデルを参照することによって推定する[1, 2, 3]。
また、最近の研究では2次元上でキーポイントを予測し[5]、PnPによって姿勢を算出することが可能になる[4]。また、画像からオブジェクトの姿勢を直接推定する手法も提案されている[6]。
RGB-Dカメラを用いた姿勢推定問題では奥行き情報を使用できるため参照できる情報量の増加により精度が向上している[7]。また、Densefusionは同様にRGB-D画像を用いて姿勢推定問題に取り組んだ[8]。
姿勢検出においてオクルージョンと呼ばれる手前にある物体が後ろにある物体を隠す問題が課題となっていたが、独自のネットワーク検出方法により、他のネットワークよりも優れた精度を示している。
6D姿勢推定を行うネットワークであるGeneralizable Model-Free 6-DoF Object Pose Estimation from RGB Images(Gen6D)を紹介する[9]。姿勢推定に必要な主なデータセットは
3次元データやカラー画像、深度データなどが代表的である。しかし、3次元データをデータセットに使用するには事前に、認識したいオブジェクトの3Dモデルを作る必要があるため、大きな手間が生じてしまう。
そのため、Gen6Dはデータセットに3Dデータを必要とせずカラー画像のみで物体の姿勢推定を行える手法を提案した。データセットにはColmapと呼ばれる2次元画像から3次元点群を再構築するために使用されるソフトウェアが用いられている[11]。
ColmapはStructure from Motion(SfM)という技術で異なる視点からの写真を使用して３次元形状を復元でき、その点群データを学習して物体の6D姿勢を推定する。\\
\begin{figure}[htbt]
	\centering
	 \includegraphics[height=55mm]{gen6d-network.eps}
	 \caption{Gen6Dネットワーク構造}
	 \label{fig:f2}
\end{figure}

Gen6Dのネットワーク構成について図3に示す。まず、Detectorと呼ばれる工程では参照画像の情報をもとに認識したいオブジェクトの領域を検出する。
次の工程である、SelectorではDetectorで得られた領域の画像と最も近い視点を持つ参照画像を複数枚ある中から1つ抽出する。
これは選択された参照画像の視点をテスト画像の視点とほぼ同様とみなし、誤差は生じますがオブジェクトのポーズの初期姿勢を形成する．
最後の工程では先程得られた姿勢の改良を試みる。まず、参照画像から近い視点の画像をさらに６枚選択し、全参照画像間の平均と分散を算出し、
初期に求められた姿勢の情報を改善して最終的な結果を予測する。この研究のメリットとしてRGB画像のみを用意することで物体の姿勢を推定できるため、
データセットの作成は非常に容易である。しかし、このGen6Dをしようするにあたって問題点が2つある。まず、一つ目にRGB画像は距離情報を持たないため、
物体のスケール情報を明示することはできない。２つ目は一度の推論で複数の物体の姿勢推定を行うことができない点である。\\

アイソメ図作成にあたって、画像内の全ての配管の位置情報、姿勢情報、距離情報は必要不可欠である。これらの情報を機械学習を用いて自動的に推定しアイソメ図を作成することができれば従来の手法よりも高効率化を図ることが期待できる。
そのため、本研究ではRGB-Dカメラを用いた深層学習によるアイソメ図の作成について取り組む。

\section{研究目的}
　本研究ではRGBDデータを使用した深層学習による配管6D姿勢推定を行い、RGBDカメラを用いることによる安価な機器での姿勢推定の実現を試みる．
また，既存のRGB画像のネットワークにDepth画像を組み込んだモデルを提案し、認識精度向上と推定速度の高速化を目標とする。
本研究の貢献は以下のようになる。まず一つ目は深層学習によるRGB画像とDepth画像を用いた物体検出ネットワーク(RXD)の提案である。
RGB画像とDepth画像からそれぞれ抽出された特徴を結合するRxDLayerを導入し、他のネットワークと比較しRXDネットワークの有効性を示した。\\
2つ目は既存の6D姿勢推定ネットワーク(Gen6D)の複数物体検出を可能にさせたことである。配管は単体ではなく複数の管が張り巡らされているため、複数の
認識を可能にする必要がある。RXDネットワークでは画像内部にある配管全てを網羅し、それぞれの物体の中心ピクセル座標とスケールを推定することができる。\\
3つ目は本研究の最終目的であるアイソメ図を作成するにあたっての必要不可欠な配管距離測定である。アイソメ図は配管の向きだけでなく、距離情報を図面に
示す必要がある。そのため、Depth画像を用いることでネットワークによって認識された情報をもとに、配管の距離情報を算出することを可能にした。

\section{本手引の構成}
 本論文の構成は以下のようになる。第一章では研究背景、既存研究、研究目的について述べる。研究背景では、
Building Information Modeling(BIM)についてや従来のアイソメ図の取得方法について述べる。
既存研究では、6D姿勢推定と物体検出のそれぞれのネットワークを紹介する。
研究目的では、本研究の目的及び貢献について述べる。\\
第2章では，データ収集から配管アイソメ図までの方法や流れについて説明する。また、RXDネットワークの提案と構造図について紹介する．
第3章では，データセットの概要について述べる。データセットを収集する機器についてやRGB-Dカメラを使用するに適した配管のデータセットについて紹介する。
第4章では，物体検出や姿勢推定をテスト画像の結果や評価指標に基づいた数値より考察する．
第5章は結言である．
